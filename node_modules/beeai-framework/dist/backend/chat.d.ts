import { Message, AssistantMessage, MessageContentPart } from './message.js';
import * as ai from 'ai';
import { Run, GetRunContext } from '../context.js';
import { Serializable } from '../internals/serializable.js';
import { C as Callback, E as Emitter } from '../emitter-l0W9gC1A.js';
import { FrameworkError } from '../errors.js';
import { Task } from 'promise-based-task';
import { BaseCache } from '../cache/base.js';
import { FullModelName } from './utils.js';
import { ProviderName } from './constants.js';
import { AnyTool } from '../tools/base.js';
import { LanguageModelV1FunctionTool, LanguageModelV1ProviderDefinedTool, LanguageModelV1ToolChoice, JSONSchema7 } from '@ai-sdk/provider';
import { z } from 'zod';
import '../internals/helpers/promise.js';
import '../internals/types.js';
import '../internals/helpers/guards.js';
import 'ajv';
import '../internals/helpers/schema.js';
import 'zod-to-json-schema';

interface ChatModelParameters {
    maxTokens?: number;
    topP?: number;
    frequencyPenalty?: number;
    temperature?: number;
    topK?: number;
    n?: number;
    presencePenalty?: number;
    seed?: number;
    stopSequences?: string[];
}
interface ChatModelObjectInput<T> extends ChatModelParameters {
    schema: z.ZodSchema<T>;
    messages: Message[];
    abortSignal?: AbortSignal;
    maxRetries?: number;
}
interface ChatModelObjectOutput<T> {
    object: T;
}
interface ChatModelInput extends ChatModelParameters {
    tools?: AnyTool[];
    abortSignal?: AbortSignal;
    stopSequences?: string[];
    responseFormat?: {
        type: "regular";
        tools?: (LanguageModelV1FunctionTool | LanguageModelV1ProviderDefinedTool)[];
        toolChoice?: LanguageModelV1ToolChoice;
    } | {
        type: "object-json";
        schema?: JSONSchema7;
        name?: string;
        description?: string;
    } | {
        type: "object-tool";
        tool: LanguageModelV1FunctionTool;
    };
    toolChoice?: never;
    messages: Message[];
}
type ChatModelFinishReason = "stop" | "length" | "content-filter" | "tool-calls" | "error" | "other" | "unknown";
interface ChatModelUsage {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
}
interface ChatModelEvents {
    newToken?: Callback<{
        value: ChatModelOutput;
        callbacks: {
            abort: () => void;
        };
    }>;
    success?: Callback<{
        value: ChatModelOutput;
    }>;
    start?: Callback<{
        input: ChatModelInput;
    }>;
    error?: Callback<{
        input: ChatModelInput;
        error: FrameworkError;
    }>;
    finish?: Callback<null>;
}
type ChatModelEmitter<A = Record<never, never>> = Emitter<ChatModelEvents & Omit<A, keyof ChatModelEvents>>;
type ChatModelCache = BaseCache<Task<ChatModelOutput[]>>;
type ConfigFn<T> = (value: T) => T;
interface ChatConfig {
    cache?: ChatModelCache | ConfigFn<ChatModelCache>;
    parameters?: ChatModelParameters | ConfigFn<ChatModelParameters>;
}
declare abstract class ChatModel extends Serializable {
    abstract readonly emitter: Emitter<ChatModelEvents>;
    cache: ChatModelCache;
    parameters: ChatModelParameters;
    abstract get modelId(): string;
    abstract get providerId(): string;
    create(input: ChatModelInput & {
        stream?: boolean;
    }): Run<ChatModelOutput, this, readonly [ChatModelInput & {
        stream?: boolean;
    }]>;
    createStructure<T>(input: ChatModelObjectInput<T>): Run<ChatModelObjectOutput<T>, this, readonly [ChatModelObjectInput<T>]>;
    config({ cache, parameters }: ChatConfig): void;
    static fromName(name: FullModelName | ProviderName, options?: ChatModelParameters): Promise<ChatModel>;
    protected abstract _create(input: ChatModelInput, run: GetRunContext<typeof this>): Promise<ChatModelOutput>;
    protected abstract _createStream(input: ChatModelInput, run: GetRunContext<typeof this>): AsyncGenerator<ChatModelOutput, void>;
    protected _createStructure<T>(input: ChatModelObjectInput<T>, run: GetRunContext<typeof this>): Promise<ChatModelObjectOutput<T>>;
    createSnapshot(): {
        cache: ChatModelCache;
        emitter: Emitter<ChatModelEvents>;
        parameters: ChatModelParameters;
    };
    destroy(): void;
    protected createCacheAccessor({ abortSignal: _, messages, tools, ...input }: ChatModelInput): Promise<{
        key: string;
        value: ChatModelOutput[] | undefined;
        resolve: <T2 extends ChatModelOutput>(value: T2[]) => void;
        reject: (error: Error) => Promise<void>;
    }>;
}
declare class ChatModelOutput extends Serializable {
    readonly messages: Message[];
    usage?: ChatModelUsage | undefined;
    finishReason?: ChatModelFinishReason | undefined;
    constructor(messages: Message[], usage?: ChatModelUsage | undefined, finishReason?: ChatModelFinishReason | undefined);
    static fromChunks(chunks: ChatModelOutput[]): ChatModelOutput;
    merge(other: ChatModelOutput): void;
    getToolCalls(): ai.ToolCallPart[];
    getTextMessages(): AssistantMessage[];
    getTextContent(): string;
    toString(): string;
    createSnapshot(): {
        messages: Message<MessageContentPart, string>[];
        usage: ChatModelUsage | undefined;
        finishReason: ChatModelFinishReason | undefined;
    };
    loadSnapshot(snapshot: ReturnType<typeof this.createSnapshot>): void;
}

export { type ChatConfig, ChatModel, type ChatModelCache, type ChatModelEmitter, type ChatModelEvents, type ChatModelFinishReason, type ChatModelInput, type ChatModelObjectInput, type ChatModelObjectOutput, ChatModelOutput, type ChatModelParameters, type ChatModelUsage, type ConfigFn };
