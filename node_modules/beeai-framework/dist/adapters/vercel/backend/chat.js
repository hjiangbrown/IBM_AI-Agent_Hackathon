import { ChatModel, ChatModelOutput } from '../../../backend/chat.js';
import { generateText, generateObject, streamText, jsonSchema } from 'ai';
import { Emitter } from '../../../emitter/emitter.js';
import { ToolMessage, AssistantMessage } from '../../../backend/message.js';
import { ValueError } from '../../../errors.js';
import { toCamelCase, isEmpty, mapToObj } from 'remeda';
import { ChatModelError } from '../../../backend/errors.js';
import { ZodArray, ZodEnum } from 'zod';

var __defProp = Object.defineProperty;
var __name = (target, value) => __defProp(target, "name", { value, configurable: true });
class VercelChatModel extends ChatModel {
  static {
    __name(this, "VercelChatModel");
  }
  model;
  emitter;
  supportsToolStreaming;
  constructor(model) {
    super(), this.model = model, this.supportsToolStreaming = true;
    if (!this.modelId) {
      throw new ValueError("No modelId has been provided!");
    }
    this.emitter = Emitter.root.child({
      namespace: [
        "backend",
        this.providerId,
        "chat"
      ],
      creator: this
    });
  }
  get modelId() {
    return this.model.modelId;
  }
  get providerId() {
    const provider = this.model.provider.split(".")[0].split("-")[0];
    return toCamelCase(provider);
  }
  async _create(input, _run) {
    const { finishReason, usage, response: { messages } } = await generateText(await this.transformInput(input));
    return new ChatModelOutput(this.transformMessages(messages), usage, finishReason);
  }
  async _createStructure({ schema, ...input }, run) {
    const inputSchema = schema._input || schema;
    const response = await generateObject({
      temperature: 0,
      ...await this.transformInput(input),
      schema,
      abortSignal: run.signal,
      model: this.model,
      // @ts-expect-error
      output: inputSchema instanceof ZodArray ? "array" : inputSchema instanceof ZodEnum ? "enum" : "object"
    });
    return {
      object: response.object
    };
  }
  async *_createStream(input, run) {
    if (!this.supportsToolStreaming && !isEmpty(input.tools ?? [])) {
      const response2 = await this._create(input, run);
      yield response2;
      return;
    }
    const { fullStream, usage, finishReason, response } = streamText({
      ...await this.transformInput(input),
      abortSignal: run.signal
    });
    let lastChunk = null;
    for await (const event of fullStream) {
      let message;
      switch (event.type) {
        case "text-delta":
          message = new AssistantMessage(event.textDelta);
          break;
        case "tool-call":
          message = new AssistantMessage({
            type: event.type,
            toolCallId: event.toolCallId,
            toolName: event.toolName,
            args: event.args
          });
          break;
        case "error":
          throw new ChatModelError("Unhandled error", [
            event.error
          ]);
        case "step-finish":
        case "step-start":
          continue;
        case "tool-result":
          message = new ToolMessage({
            type: event.type,
            toolCallId: event.toolCallId,
            toolName: event.toolName,
            result: event.result
          });
          break;
        case "tool-call-streaming-start":
        case "tool-call-delta":
          continue;
        case "finish":
          continue;
        default:
          throw new Error(`Unhandled event "${event.type}"`);
      }
      lastChunk = new ChatModelOutput([
        message
      ]);
      yield lastChunk;
    }
    if (!lastChunk) {
      throw new ChatModelError("No chunks have been received!");
    }
    lastChunk.usage = await usage;
    lastChunk.finishReason = await finishReason;
    await response;
  }
  async transformInput(input) {
    const tools = await Promise.all((input.tools ?? []).map(async (tool) => ({
      name: tool.name,
      description: tool.description,
      parameters: jsonSchema(await tool.getInputJsonSchema())
    })));
    const messages = input.messages.map((msg) => {
      if (msg instanceof AssistantMessage) {
        return {
          role: "assistant",
          content: msg.content
        };
      } else if (msg instanceof ToolMessage) {
        return {
          role: "tool",
          content: msg.content
        };
      }
      return {
        role: msg.role,
        content: msg.text
      };
    });
    return {
      ...this.parameters,
      ...input,
      model: this.model,
      tools: mapToObj(tools, ({ name, ...tool }) => [
        name,
        tool
      ]),
      messages
    };
  }
  transformMessages(messages) {
    return messages.flatMap((msg) => {
      if (msg.role === "tool") {
        return new ToolMessage(msg.content, msg.providerOptions);
      }
      return new AssistantMessage(msg.content, msg.providerOptions);
    });
  }
  createSnapshot() {
    return {
      ...super.createSnapshot(),
      providerId: this.providerId,
      modelId: this.modelId,
      supportsToolStreaming: this.supportsToolStreaming
    };
  }
  async loadSnapshot({ providerId, modelId, ...snapshot }) {
    const instance = await ChatModel.fromName(`${providerId}:${modelId}`);
    if (!(instance instanceof VercelChatModel)) {
      throw new Error("Incorrect deserialization!");
    }
    instance.destroy();
    Object.assign(this, {
      ...snapshot,
      model: instance.model
    });
  }
}

export { VercelChatModel };
//# sourceMappingURL=chat.js.map
//# sourceMappingURL=chat.js.map